from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer


model_name = 'facebook/m2m100_418M'
tokenizer = M2M100Tokenizer.from_pretrained(model_name)
model = M2M100ForConditionalGeneration.from_pretrained(model_name)



def translate_text(text: str) -> str:
    tokenizer.src_lang = "ko"
    encoded = tokenizer(text, return_tensors="pt")

    generated_tokens = model.generate(
    **encoded,
    forced_bos_token_id=tokenizer.get_lang_id("en")   # ë²ˆì—­í•  ì–¸ì–´
    )

    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
    print(f"ğŸŒ ë²ˆì—­: '{text}' â†’ '{translation}'")
    return translation



if __name__ == "__main__":
    print(translate_text("í„¸ìƒ‰ë§Œ ê²€ì •ìƒ‰ìœ¼ë¡œ ë°”ê¿”ì¤˜"))